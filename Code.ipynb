{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from typing import Any, List, Dict, Tuple, Callable, Iterable, Optional\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df78864",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device('cuda')\n",
    "else:\n",
    "    dev = torch.device('cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = int(np.pi * 100_000_000)\n",
    "torch.random.manual_seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random.seed(seed + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_data_dir = 'data/skewed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de891db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_syst = torch.tensor(np.sort(np.concatenate([\n",
    "    np.arange(88, 97) / 100,\n",
    "    np.arange(970, 1030) / 1000,\n",
    "    np.arange(103, 107) / 100,\n",
    "    np.arange(1070, 1130) / 1000,\n",
    "    np.arange(113, 115) / 100,\n",
    "], axis=-1)))\n",
    "z_syst_up = 1.1 \n",
    "z_syst_down = 0.8 \n",
    "z_nominal = 1.0\n",
    "\n",
    "z_syst_train = torch.tensor([\n",
    "    0.7,  0.74, 0.78, 0.8,  0.84, 0.88, 0.9,  0.92,\n",
    "    0.94, 0.96, 0.98, 0.99, 1.0,  1.01, 1.02, 1.04,\n",
    "    1.06, 1.08, 1.09, 1.10, 1.11, 1.12, 1.13, 1.14,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    x: torch.Tensor\n",
    "    y: torch.Tensor\n",
    "    z: torch.Tensor\n",
    "    weights: torch.Tensor\n",
    "        \n",
    "    def __getitem__(self, index) -> 'Dataset':\n",
    "        return Dataset(\n",
    "            x=self.x[index],\n",
    "            y=self.y[index],\n",
    "            z=self.z[index],\n",
    "            weights=self.weights[index],\n",
    "        )\n",
    "        \n",
    "    def __setitem__(self, index, item: 'Dataset') -> None:\n",
    "        self.x[index] = item.x\n",
    "        self.y[index] = item.y\n",
    "        self.z[index] = item.z\n",
    "        self.weights[index] = item.weights\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.x)\n",
    "    \n",
    "    def sizeof(self) -> int:\n",
    "        return sum(\n",
    "            reduce(lambda a, b: a * b, tensor.shape) * tensor.element_size()\n",
    "            for tensor in [\n",
    "                self.x,\n",
    "                self.y,\n",
    "                self.z,\n",
    "                self.weights,\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def to(self, device) -> 'Dataset':\n",
    "        return Dataset(\n",
    "            x=self.x.to(device),\n",
    "            y=self.y.to(device),\n",
    "            z=self.z.to(device),\n",
    "            weights=self.weights.to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x, device=None) -> torch.Tensor:\n",
    "    if device is None:\n",
    "        device = dev\n",
    "    if isinstance(x, (pd.DataFrame, pd.Series)):\n",
    "        return torch.tensor(x.values.astype(np.float32)).to(device)\n",
    "    if isinstance(x, (np.ndarray, list)):\n",
    "        return torch.tensor(x).to(device)\n",
    "    raise TypeError(f'Unknown type {type(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(x, y, z, weights) -> Dataset:\n",
    "    return Dataset(\n",
    "        x=to_tensor(x, device='cpu'),\n",
    "        y=to_tensor(y, device='cpu'),\n",
    "        z=to_tensor(z, device='cpu'),\n",
    "        weights=to_tensor(weights, device='cpu'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data_for(z: float) -> Tuple[Dataset, Dataset]:\n",
    "    path = os.path.join(skewed_data_dir, f'HiggsML_TES_{round(z, 2)}.h5')\n",
    "    # Read and shuffle.\n",
    "    df = pd.read_hdf(path, 'data_syst').sample(frac=1).reset_index()\n",
    "    \n",
    "    target = df['Label'] == 'b'\n",
    "    weights = df['Weight']\n",
    "    z = df['Z']\n",
    "    assert (z == z[0]).all()\n",
    "    indices = df['index']\n",
    "    df.drop(['Label', 'Z', 'Weight', 'index', 'KaggleSet'], axis=1, inplace=True)\n",
    "    \n",
    "    train_indices = indices % 2 == 0\n",
    "    train_set = make_dataset(\n",
    "        x=df[train_indices],\n",
    "        y=target[train_indices],\n",
    "        z=z[train_indices],\n",
    "        weights=weights[train_indices],\n",
    "    )\n",
    "    \n",
    "    test_indices = ~train_indices\n",
    "    test_set = make_dataset(\n",
    "        x=df[test_indices],\n",
    "        y=target[test_indices],\n",
    "        z=z[test_indices],\n",
    "        weights=weights[test_indices],\n",
    "    )\n",
    "    \n",
    "    scale_up = 1.0\n",
    "    class_weights = (\n",
    "        weights[target == 0].sum(),\n",
    "        weights[target == 1].sum(),\n",
    "    )\n",
    "    test_class_weights = (\n",
    "        test_set.weights[test_set.y == 0].sum(),\n",
    "        test_set.weights[test_set.y == 1].sum(),\n",
    "    )\n",
    "    \n",
    "    for label in (0, 1):\n",
    "        factor_train = scale_up * max(class_weights) / class_weights[label]\n",
    "        train_set.weights[train_set.y == label] *= factor_train\n",
    "        factor_test = class_weights[label] / test_class_weights[label]\n",
    "        test_set.weights[test_set.y == label] *= factor_test\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_datasets(datasets: List[Dataset]) -> Dataset:\n",
    "    x = [data.x for data in datasets]\n",
    "    y = [data.y for data in datasets]\n",
    "    z = [data.z for data in datasets]\n",
    "    weights = [data.weights for data in datasets]\n",
    "    return Dataset(\n",
    "        x=torch.cat(x),\n",
    "        y=torch.cat(y),\n",
    "        z=torch.cat(z),\n",
    "        weights=torch.cat(weights),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(collection):\n",
    "    return collection[torch.randperm(len(collection))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8612ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(\n",
    "    z_values: List[float],\n",
    ") -> Tuple[Dataset, Dataset, StandardScaler]:\n",
    "    train_datasets: List[Dataset] = []\n",
    "    test_datasets: List[Dataset] = []\n",
    "    \n",
    "    total_size = 0\n",
    "    for z in tqdm(z_values):\n",
    "        train_dataset, test_dataset = load_training_data_for(float(z))\n",
    "        train_datasets.append(train_dataset)\n",
    "        current_size = train_dataset.sizeof() + test_dataset.sizeof()\n",
    "        total_size += current_size\n",
    "        print(f'z = {z:.2f}, size = {current_size >> 20}M, total size = {total_size >> 20}M')\n",
    "        test_datasets.append(test_dataset)\n",
    "    \n",
    "    train_cat = concat_datasets(train_datasets)\n",
    "    test_cat = concat_datasets(test_datasets)\n",
    "    train_cat = shuffle(train_cat)\n",
    "    test_cat = shuffle(test_cat)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_cat.x = torch.tensor(scaler.fit_transform(train_cat.x), dtype=torch.float32)\n",
    "    test_cat.x = torch.tensor(scaler.transform(test_cat.x), dtype=torch.float32)\n",
    "    \n",
    "    return train_cat, test_cat, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb180696",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_train, data_test, scaler = load_training_data(z_syst_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.to(dev)\n",
    "data_test = data_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e9c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, num_hidden_layers: int, num_hidden_nodes: int):\n",
    "        super().__init__()\n",
    "        input_layer = nn.Sequential(\n",
    "            nn.Linear(data_train.x.shape[1], num_hidden_nodes),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        hidden_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            for _ in range(num_hidden_layers - 1)\n",
    "        ]\n",
    "        output_layer = nn.Sequential(\n",
    "            nn.Linear(num_hidden_nodes, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self._layers = nn.Sequential(input_layer, *hidden_layers, output_layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    num_epochs: int,\n",
    "    batch_size: int,\n",
    "    dataset_filter: Optional[torch.Tensor] = None,\n",
    "    Optimizer = torch.optim.RMSprop,\n",
    "    include_z: bool = False,\n",
    "):\n",
    "    dataset = data_train\n",
    "    if dataset_filter is not None:\n",
    "        dataset = data_train[dataset_filter]\n",
    "        \n",
    "    opt = Optimizer(model.parameters(), weight_decay=0.0001)\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        dataset.x,\n",
    "        dataset.y,\n",
    "        dataset.z,\n",
    "        dataset.weights,\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "    for epoch in trange(num_epochs):\n",
    "        total_loss_value = 0.0\n",
    "        num_correct = 0\n",
    "        for x, y, z, weights in tqdm(loader, leave=False):\n",
    "            opt.zero_grad()\n",
    "            inputs = (x, z) if include_z else x\n",
    "            y_pred = model(inputs).flatten()\n",
    "            loss_value = nn.BCELoss(weight=weights)(y_pred, y)\n",
    "            loss_value.backward()\n",
    "            with torch.no_grad():\n",
    "                total_loss_value += float(loss_value) * len(x)\n",
    "                num_correct += int(((y_pred > 0.5) == (y > 0.5)).sum())\n",
    "            opt.step()\n",
    "        accuracy = num_correct / len(dataset)\n",
    "        total_loss_value /= len(dataset)\n",
    "        print(f'Epoch {epoch+1}: loss = {total_loss_value:.5f}, accuracy = {accuracy:.5f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Evaluation:\n",
    "    accuracy: float\n",
    "    loss: float\n",
    "        \n",
    "def evaluate(\n",
    "    model,\n",
    "    dataset,\n",
    "    dataset_filter: Optional[torch.Tensor] = None,\n",
    "    z = None,\n",
    "    temp_gpu: bool = True,\n",
    "    leave_progress_bar: bool = True,\n",
    "):\n",
    "    if temp_gpu:\n",
    "        model.to(dev)\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            if dataset_filter is not None:\n",
    "                dataset = dataset[dataset_filter]\n",
    "            if z is None:\n",
    "                test_dataset = torch.utils.data.TensorDataset(\n",
    "                    dataset.x,\n",
    "                    dataset.y,\n",
    "                    dataset.z,\n",
    "                    dataset.weights,\n",
    "                )\n",
    "            else:\n",
    "                test_dataset = torch.utils.data.TensorDataset(\n",
    "                    dataset.x,\n",
    "                    dataset.y,\n",
    "                    z,\n",
    "                    dataset.weights,\n",
    "                )\n",
    "            loader = torch.utils.data.DataLoader(test_dataset, batch_size=4096, shuffle=True)\n",
    "            loss_value = 0.0\n",
    "            num_correct = 0\n",
    "            for x, y, zvalue, weights in tqdm(loader, leave=leave_progress_bar):\n",
    "                inputs = x if z is None else (x, zvalue)\n",
    "                y_pred = model(inputs).flatten()\n",
    "                loss_value += float(nn.BCELoss(weight=weights)(y_pred, y)) * len(x)\n",
    "                num_correct += int(((y_pred > 0.5) == (y > 0.5)).sum())\n",
    "\n",
    "            accuracy = num_correct / len(dataset)\n",
    "            return Evaluation(accuracy=accuracy, loss=loss_value/len(dataset))\n",
    "    finally:\n",
    "        if temp_gpu:\n",
    "            model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79258f26",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb2763",
   "metadata": {},
   "source": [
    "### Baseline model (nominal z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9037b94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "baseline_nominal_model = train(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=512).to(dev),\n",
    "    num_epochs=200,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    dataset_filter=torch.isclose(data_train.z, torch.tensor(z_nominal, dtype=torch.float32)),\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    baseline_nominal_model,\n",
    "    data_test,\n",
    "    torch.isclose(data_test.z, torch.tensor(z_nominal, dtype=torch.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.baseline-nominal.pt', 'wb') as f:\n",
    "    torch.save(baseline_nominal_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20eb91",
   "metadata": {},
   "source": [
    "### Baseline model (low z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_down_model = train(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=64).to(dev),\n",
    "    num_epochs=200,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    dataset_filter=torch.isclose(data_train.z, torch.tensor(z_syst_down, dtype=torch.float32)),\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24315671",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    baseline_down_model,\n",
    "    data_test,\n",
    "    torch.isclose(data_test.z, torch.tensor(z_syst_down, dtype=torch.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1148d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.baseline-down.pt', 'wb') as f:\n",
    "    torch.save(baseline_down_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c216f8",
   "metadata": {},
   "source": [
    "### Baseline model (high z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a89f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_up_model = train(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=512).to(dev),\n",
    "    num_epochs=200,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    dataset_filter=torch.isclose(data_train.z, torch.tensor(z_syst_up, dtype=torch.float32)),\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    baseline_up_model,\n",
    "    data_test,\n",
    "    torch.isclose(data_test.z, torch.tensor(z_syst_up, dtype=torch.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.baseline-up.pt', 'wb') as f:\n",
    "    torch.save(baseline_up_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705da40b",
   "metadata": {},
   "source": [
    "### Data augmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_model = train(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=64).to(dev),\n",
    "    num_epochs=10,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.Adam(*a, **k, lr=0.001),\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ec9f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    aug_model,\n",
    "    data_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.aug.pt', 'wb') as f:\n",
    "    torch.save(aug_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525ea0f",
   "metadata": {},
   "source": [
    "### Uncertainty aware model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UncertaintyAwareModel(nn.Module):\n",
    "    def __init__(self, num_hidden_layers: int, num_hidden_nodes: int):\n",
    "        super().__init__()\n",
    "        self._layers_a = UncertaintyAwareModel.create_layers(num_hidden_layers, num_hidden_nodes)\n",
    "        self._layers_b = UncertaintyAwareModel.create_layers(num_hidden_layers, num_hidden_nodes)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_layers(num_hidden_layers: int, num_hidden_nodes: int):\n",
    "        input_layer = nn.Sequential(\n",
    "            nn.Linear(data_train.x.shape[1] + 1, num_hidden_nodes),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        hidden_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            for _ in range(num_hidden_layers - 1)\n",
    "        ]\n",
    "        output_layer = nn.Sequential(\n",
    "            nn.Linear(num_hidden_nodes, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return nn.Sequential(input_layer, *hidden_layers, output_layer)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x, z = inputs\n",
    "        z = z.view((len(z), 1))\n",
    "        input_tensor = torch.cat([x, z], dim=1)\n",
    "        \n",
    "        a = self._layers_a(input_tensor)\n",
    "        b = self._layers_b(input_tensor)\n",
    "        return torch.where(z < 1, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe80c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_model = train(\n",
    "    UncertaintyAwareModel(num_hidden_layers=10, num_hidden_nodes=64).to(dev),\n",
    "    num_epochs=15,\n",
    "    batch_size=2048,\n",
    "    include_z=True,\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4dc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(aware_model, data_test, z=data_test.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9921320",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.aware.pt', 'wb') as f:\n",
    "    torch.save(aware_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
