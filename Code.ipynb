{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4fbaaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from pytorch_revgrad import RevGrad\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from typing import Any, List, Dict, Tuple, Callable, Iterable, Optional\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df78864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device('cuda')\n",
    "else:\n",
    "    dev = torch.device('cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a95031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = int(np.pi * 100_000_000)\n",
    "torch.random.manual_seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random.seed(seed + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eda0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_data_dir = 'data/skewed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd73d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_syst = torch.tensor(np.sort(np.concatenate([\n",
    "    np.arange(88, 97) / 100,\n",
    "    np.arange(970, 1030) / 1000,\n",
    "    np.arange(103, 107) / 100,\n",
    "    np.arange(1070, 1130) / 1000,\n",
    "    np.arange(113, 115) / 100,\n",
    "], axis=-1)))\n",
    "z_syst_up = 1.1 \n",
    "z_syst_down = 0.8 \n",
    "z_nominal = 1.0\n",
    "\n",
    "z_syst_train = torch.tensor([\n",
    "    0.7,  0.74, 0.78, 0.8,  0.84, 0.88, 0.9,  0.92,\n",
    "    0.94, 0.96, 0.98, 0.99, 1.0,  1.01, 1.02, 1.04,\n",
    "    1.06, 1.08, 1.09, 1.10, 1.11, 1.12, 1.13, 1.14,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de9bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    x: torch.Tensor\n",
    "    y: torch.Tensor\n",
    "    z: torch.Tensor\n",
    "    weights: torch.Tensor\n",
    "        \n",
    "    def __getitem__(self, index) -> 'Dataset':\n",
    "        return Dataset(\n",
    "            x=self.x[index],\n",
    "            y=self.y[index],\n",
    "            z=self.z[index],\n",
    "            weights=self.weights[index],\n",
    "        )\n",
    "        \n",
    "    def __setitem__(self, index, item: 'Dataset') -> None:\n",
    "        self.x[index] = item.x\n",
    "        self.y[index] = item.y\n",
    "        self.z[index] = item.z\n",
    "        self.weights[index] = item.weights\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.x)\n",
    "    \n",
    "    def sizeof(self) -> int:\n",
    "        return sum(\n",
    "            reduce(lambda a, b: a * b, tensor.shape) * tensor.element_size()\n",
    "            for tensor in [\n",
    "                self.x,\n",
    "                self.y,\n",
    "                self.z,\n",
    "                self.weights,\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def to(self, device) -> 'Dataset':\n",
    "        return Dataset(\n",
    "            x=self.x.to(device),\n",
    "            y=self.y.to(device),\n",
    "            z=self.z.to(device),\n",
    "            weights=self.weights.to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c0f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x, device=None) -> torch.Tensor:\n",
    "    if device is None:\n",
    "        device = dev\n",
    "    if isinstance(x, (pd.DataFrame, pd.Series)):\n",
    "        return torch.tensor(x.values.astype(np.float32)).to(device)\n",
    "    if isinstance(x, (np.ndarray, list)):\n",
    "        return torch.tensor(x).to(device)\n",
    "    raise TypeError(f'Unknown type {type(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5869e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(x, y, z, weights) -> Dataset:\n",
    "    return Dataset(\n",
    "        x=to_tensor(x, device='cpu'),\n",
    "        y=to_tensor(y, device='cpu'),\n",
    "        z=to_tensor(z, device='cpu'),\n",
    "        weights=to_tensor(weights, device='cpu'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416b63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data_for(z: float) -> Tuple[Dataset, Dataset]:\n",
    "    path = os.path.join(skewed_data_dir, f'HiggsML_TES_{round(z, 2)}.h5')\n",
    "    # Read and shuffle.\n",
    "    df = pd.read_hdf(path, 'data_syst').sample(frac=1).reset_index()\n",
    "    \n",
    "    target = df['Label'] == 'b'\n",
    "    weights = df['Weight']\n",
    "    z = df['Z']\n",
    "    assert (z == z[0]).all()\n",
    "    indices = df['index']\n",
    "    df.drop(['Label', 'Z', 'Weight', 'index', 'KaggleSet'], axis=1, inplace=True)\n",
    "    \n",
    "    train_indices = indices % 2 == 0\n",
    "    train_set = make_dataset(\n",
    "        x=df[train_indices],\n",
    "        y=target[train_indices],\n",
    "        z=z[train_indices],\n",
    "        weights=weights[train_indices],\n",
    "    )\n",
    "    \n",
    "    test_indices = ~train_indices\n",
    "    test_set = make_dataset(\n",
    "        x=df[test_indices],\n",
    "        y=target[test_indices],\n",
    "        z=z[test_indices],\n",
    "        weights=weights[test_indices],\n",
    "    )\n",
    "    \n",
    "    scale_up = 1.0\n",
    "    class_weights = (\n",
    "        weights[target == 0].sum(),\n",
    "        weights[target == 1].sum(),\n",
    "    )\n",
    "    test_class_weights = (\n",
    "        test_set.weights[test_set.y == 0].sum(),\n",
    "        test_set.weights[test_set.y == 1].sum(),\n",
    "    )\n",
    "    \n",
    "    for label in (0, 1):\n",
    "        factor_train = scale_up * max(class_weights) / class_weights[label]\n",
    "        train_set.weights[train_set.y == label] *= factor_train\n",
    "        factor_test = class_weights[label] / test_class_weights[label]\n",
    "        test_set.weights[test_set.y == label] *= factor_test\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5c03186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_datasets(datasets: List[Dataset]) -> Dataset:\n",
    "    x = [data.x for data in datasets]\n",
    "    y = [data.y for data in datasets]\n",
    "    z = [data.z for data in datasets]\n",
    "    weights = [data.weights for data in datasets]\n",
    "    return Dataset(\n",
    "        x=torch.cat(x),\n",
    "        y=torch.cat(y),\n",
    "        z=torch.cat(z),\n",
    "        weights=torch.cat(weights),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7075cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(collection):\n",
    "    return collection[torch.randperm(len(collection))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8612ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(\n",
    "    z_values: List[float],\n",
    ") -> Tuple[Dataset, Dataset, StandardScaler]:\n",
    "    train_datasets: List[Dataset] = []\n",
    "    test_datasets: List[Dataset] = []\n",
    "    \n",
    "    total_size = 0\n",
    "    for z in tqdm(z_values):\n",
    "        train_dataset, test_dataset = load_training_data_for(float(z))\n",
    "        train_datasets.append(train_dataset)\n",
    "        current_size = train_dataset.sizeof() + test_dataset.sizeof()\n",
    "        total_size += current_size\n",
    "        print(f'z = {z:.2f}, size = {current_size >> 20}M, total size = {total_size >> 20}M')\n",
    "        test_datasets.append(test_dataset)\n",
    "    \n",
    "    train_cat = concat_datasets(train_datasets)\n",
    "    test_cat = concat_datasets(test_datasets)\n",
    "    train_cat = shuffle(train_cat)\n",
    "    test_cat = shuffle(test_cat)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_cat.x = torch.tensor(scaler.fit_transform(train_cat.x), dtype=torch.float32)\n",
    "    test_cat.x = torch.tensor(scaler.transform(test_cat.x), dtype=torch.float32)\n",
    "    \n",
    "    return train_cat, test_cat, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dcbb44c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0358cabc3c614485911aac4b8b429b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 0.70, size = 58M, total size = 58M\n",
      "z = 0.74, size = 64M, total size = 123M\n",
      "z = 0.78, size = 70M, total size = 193M\n",
      "z = 0.80, size = 73M, total size = 267M\n",
      "z = 0.84, size = 78M, total size = 345M\n",
      "z = 0.88, size = 84M, total size = 430M\n",
      "z = 0.90, size = 87M, total size = 517M\n",
      "z = 0.92, size = 90M, total size = 608M\n",
      "z = 0.94, size = 93M, total size = 701M\n",
      "z = 0.96, size = 95M, total size = 797M\n",
      "z = 0.98, size = 98M, total size = 895M\n",
      "z = 0.99, size = 100M, total size = 995M\n",
      "z = 1.00, size = 101M, total size = 1097M\n",
      "z = 1.01, size = 102M, total size = 1200M\n",
      "z = 1.02, size = 104M, total size = 1304M\n",
      "z = 1.04, size = 107M, total size = 1411M\n",
      "z = 1.06, size = 109M, total size = 1521M\n",
      "z = 1.08, size = 112M, total size = 1634M\n",
      "z = 1.09, size = 114M, total size = 1748M\n",
      "z = 1.10, size = 115M, total size = 1863M\n",
      "z = 1.11, size = 115M, total size = 1979M\n",
      "z = 1.12, size = 115M, total size = 2094M\n",
      "z = 1.13, size = 115M, total size = 2210M\n",
      "z = 1.14, size = 115M, total size = 2325M\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, scaler = load_training_data(z_syst_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427ab9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.to(dev)\n",
    "data_test = data_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1622e8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8238657, 34])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166600d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b5ac9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    num_epochs: int,\n",
    "    batch_size: int,\n",
    "    dataset_filter: Optional[torch.Tensor] = None,\n",
    "    Optimizer = torch.optim.RMSprop,\n",
    "    include_z: bool = False,\n",
    "    weight_decay: float = 0.0001,\n",
    "):\n",
    "    dataset = data_train\n",
    "    if dataset_filter is not None:\n",
    "        dataset = data_train[dataset_filter]\n",
    "        \n",
    "    opt = Optimizer(model.parameters(), weight_decay=weight_decay)\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        dataset.x,\n",
    "        dataset.y,\n",
    "        dataset.z,\n",
    "        dataset.weights,\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "    for epoch in trange(num_epochs):\n",
    "        total_loss_value = 0.0\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for x, y, z, weights in tqdm(loader, leave=False):\n",
    "            opt.zero_grad()\n",
    "            inputs = (x, z) if include_z else x\n",
    "            output = model(inputs)\n",
    "            if isinstance(output, tuple):\n",
    "                y_pred = output[0]\n",
    "            else:\n",
    "                y_pred = output\n",
    "            y_pred = y_pred.flatten()\n",
    "            \n",
    "            assert len(y_pred) == len(x)\n",
    "            \n",
    "            if hasattr(model, 'compute_loss'):\n",
    "                loss_value = model.compute_loss(output, y, weights, z)\n",
    "            else:\n",
    "                loss_value = nn.BCELoss(weight=weights)(y_pred, y)\n",
    "            loss_value.backward()\n",
    "            with torch.no_grad():\n",
    "                total_loss_value += float(loss_value) * len(x)\n",
    "                this_num_correct = int(((y_pred > 0.5) == (y > 0.5)).sum())\n",
    "                assert this_num_correct <= len(y_pred)\n",
    "                num_total += len(y_pred)\n",
    "                num_correct += this_num_correct\n",
    "            opt.step()\n",
    "        assert num_total == len(dataset)\n",
    "        accuracy = num_correct / len(dataset)\n",
    "        total_loss_value /= len(dataset)\n",
    "        print(f'Epoch {epoch+1}: loss = {total_loss_value:.5f}, accuracy = {accuracy:.5f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "00d1a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_load(*args, path, **kwargs):\n",
    "    if os.path.exists(path):\n",
    "        print(f'Loading trained model from {path}')\n",
    "        with open(path, 'rb') as f:\n",
    "            return torch.load(f)\n",
    "    return train(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b29b4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Evaluation:\n",
    "    accuracy: float\n",
    "    loss: float\n",
    "        \n",
    "def evaluate(\n",
    "    model,\n",
    "    dataset,\n",
    "    dataset_filter: Optional[torch.Tensor] = None,\n",
    "    z = None,\n",
    "    temp_gpu: bool = True,\n",
    "    leave_progress_bar: bool = True,\n",
    "):\n",
    "    if temp_gpu:\n",
    "        model.to(dev)\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            if dataset_filter is not None:\n",
    "                dataset = dataset[dataset_filter]\n",
    "            if z is None:\n",
    "                test_dataset = torch.utils.data.TensorDataset(\n",
    "                    dataset.x,\n",
    "                    dataset.y,\n",
    "                    dataset.z,\n",
    "                    dataset.weights,\n",
    "                )\n",
    "            else:\n",
    "                test_dataset = torch.utils.data.TensorDataset(\n",
    "                    dataset.x,\n",
    "                    dataset.y,\n",
    "                    z,\n",
    "                    dataset.weights,\n",
    "                )\n",
    "            loader = torch.utils.data.DataLoader(test_dataset, batch_size=4096, shuffle=True)\n",
    "            loss_value = 0.0\n",
    "            num_correct = 0\n",
    "            for x, y, zvalue, weights in tqdm(loader, leave=leave_progress_bar):\n",
    "                inputs = x if z is None else (x, zvalue)\n",
    "                \n",
    "                output = model(inputs)\n",
    "                if isinstance(output, tuple):\n",
    "                    y_pred = output[0]\n",
    "                else:\n",
    "                    y_pred = output\n",
    "                y_pred = y_pred.flatten()\n",
    "\n",
    "                assert len(y_pred) == len(x)\n",
    "\n",
    "                if hasattr(model, 'compute_loss'):\n",
    "                    loss_value += float(model.compute_loss(output, y, weights, zvalue))\n",
    "                else:\n",
    "                    loss_value += float(nn.BCELoss(weight=weights)(y_pred, y)) * len(x)\n",
    "                num_correct += int(((y_pred > 0.5) == (y > 0.5)).sum())\n",
    "\n",
    "            accuracy = num_correct / len(dataset)\n",
    "            return Evaluation(accuracy=accuracy, loss=loss_value/len(dataset))\n",
    "    finally:\n",
    "        if temp_gpu:\n",
    "            model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786395e8",
   "metadata": {},
   "source": [
    "### Baseline model (nominal z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0ba205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hidden_layers: int,\n",
    "        num_hidden_nodes: int,\n",
    "        num_inputs = None,\n",
    "        final_activation: bool = True,\n",
    "    ):\n",
    "        if num_inputs is None:\n",
    "            num_inputs = data_train.x.shape[1]\n",
    "        super().__init__()\n",
    "        input_layer = nn.Sequential(\n",
    "            nn.Linear(num_inputs, num_hidden_nodes),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        hidden_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            for _ in range(num_hidden_layers - 1)\n",
    "        ]\n",
    "        output_layer = nn.Sequential(\n",
    "            nn.Linear(num_hidden_nodes, 1),\n",
    "            nn.Sigmoid() if final_activation else nn.Identity(),\n",
    "        )\n",
    "        self._layers = nn.Sequential(input_layer, *hidden_layers, output_layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f71bbffb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model from data/model.baseline-nominal.pt\n"
     ]
    }
   ],
   "source": [
    "baseline_nominal_model = train_or_load(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=512).to(dev),\n",
    "    num_epochs=50,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    dataset_filter=torch.isclose(data_train.z, torch.tensor(z_nominal, dtype=torch.float32)),\n",
    "    path='data/model.baseline-nominal.pt',\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab323f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072b43cb2cd241248653ec6e38df24ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(accuracy=0.9262328359537064, loss=0.019609023755159338)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    baseline_nominal_model,\n",
    "    data_test,\n",
    "    torch.isclose(data_test.z, torch.tensor(z_nominal, dtype=torch.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9078c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.baseline-nominal.pt', 'wb') as f:\n",
    "    torch.save(baseline_nominal_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e71f0",
   "metadata": {},
   "source": [
    "### Baseline model (low z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c35c992f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model from data/model.baseline-down.pt\n"
     ]
    }
   ],
   "source": [
    "baseline_down_model = train_or_load(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=64).to(dev),\n",
    "    num_epochs=50,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    dataset_filter=torch.isclose(data_train.z, torch.tensor(z_syst_down, dtype=torch.float32)),\n",
    "    path='data/model.baseline-down.pt',\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e18b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df954c1ef28413db63a98f6a5ae5a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(accuracy=0.9598042049681063, loss=0.006369620191470305)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    baseline_down_model,\n",
    "    data_test,\n",
    "    torch.isclose(data_test.z, torch.tensor(z_syst_down, dtype=torch.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9be84924",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.baseline-down.pt', 'wb') as f:\n",
    "    torch.save(baseline_down_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa24a4",
   "metadata": {},
   "source": [
    "### Baseline model (high z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f9c6235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model from data/model.baseline-up.pt\n"
     ]
    }
   ],
   "source": [
    "baseline_up_model = train_or_load(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=512).to(dev),\n",
    "    num_epochs=50,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    dataset_filter=torch.isclose(data_train.z, torch.tensor(z_syst_up, dtype=torch.float32)),\n",
    "    path='data/model.baseline-up.pt',\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95f50057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4940861e50c4607a9d227bcc55a6f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(accuracy=0.9172103437571041, loss=0.024045526460747226)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    baseline_up_model,\n",
    "    data_test,\n",
    "    torch.isclose(data_test.z, torch.tensor(z_syst_up, dtype=torch.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23d71bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.baseline-up.pt', 'wb') as f:\n",
    "    torch.save(baseline_up_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84ca17",
   "metadata": {},
   "source": [
    "### Data augmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b48aca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model from data/model.aug.pt\n"
     ]
    }
   ],
   "source": [
    "aug_model = train_or_load(\n",
    "    BaselineModel(num_hidden_layers=10, num_hidden_nodes=512).to(dev),\n",
    "    num_epochs=10,\n",
    "    batch_size=2048,\n",
    "    Optimizer=lambda *a, **k: torch.optim.Adam(*a, **k, lr=0.001),\n",
    "    path='data/model.aug.pt',\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84c2db11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21488e3c5b964d198002cf8145ee4815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(accuracy=0.9626696201063024, loss=0.005541750624016032)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(aug_model, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aba9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.aug.pt', 'wb') as f:\n",
    "    torch.save(aug_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e4d08",
   "metadata": {},
   "source": [
    "### Uncertainty aware model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c84ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UncertaintyAwareModel(nn.Module):\n",
    "    def __init__(self, num_hidden_layers: int, num_hidden_nodes: int):\n",
    "        super().__init__()\n",
    "        self._layers_a = UncertaintyAwareModel.create_layers(num_hidden_layers, num_hidden_nodes)\n",
    "        self._layers_b = UncertaintyAwareModel.create_layers(num_hidden_layers, num_hidden_nodes)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_layers(num_hidden_layers: int, num_hidden_nodes: int):\n",
    "        input_layer = nn.Sequential(\n",
    "            nn.Linear(data_train.x.shape[1] + 1, num_hidden_nodes),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        hidden_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            for _ in range(num_hidden_layers - 1)\n",
    "        ]\n",
    "        output_layer = nn.Sequential(\n",
    "            nn.Linear(num_hidden_nodes, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        return nn.Sequential(input_layer, *hidden_layers, output_layer)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x, z = inputs\n",
    "        z = z.view((len(z), 1))\n",
    "        input_tensor = torch.cat([x, z], dim=1)\n",
    "        \n",
    "        a = self._layers_a(input_tensor)\n",
    "        b = self._layers_b(input_tensor)\n",
    "        return torch.where(z < 1, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82a54fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a5b190daaa4fc0a0e75247170cceab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 0.03593, accuracy = 0.91485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss = 0.01208, accuracy = 0.93731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss = 0.01044, accuracy = 0.94103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss = 0.00944, accuracy = 0.94361\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss = 0.00883, accuracy = 0.94493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: loss = 0.00847, accuracy = 0.94608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: loss = 0.00809, accuracy = 0.94732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss = 0.00772, accuracy = 0.94860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: loss = 0.00746, accuracy = 0.94980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss = 0.00729, accuracy = 0.95015\n"
     ]
    }
   ],
   "source": [
    "aware_model = train_or_load(\n",
    "    UncertaintyAwareModel(num_hidden_layers=10, num_hidden_nodes=64).to(dev),\n",
    "    num_epochs=10,\n",
    "    batch_size=2048,\n",
    "    include_z=True,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    weight_decay=0.00003,\n",
    "    path='data/model.aware.pt',\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e8bdf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f2033e17d845e8a9730be22f96efae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(accuracy=0.9466954874607458, loss=0.010065191383443146)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(aware_model, data_test, z=data_test.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8540e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.aware.pt', 'wb') as f:\n",
    "    torch.save(aware_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0031cd1e",
   "metadata": {},
   "source": [
    "### Adversarial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f9f7c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialModel(nn.Module):\n",
    "    def __init__(self, lambda_weight: float):\n",
    "        super().__init__()\n",
    "        self._lambda_weight = lambda_weight\n",
    "        self._classifier = BaselineModel(\n",
    "            num_hidden_layers=10, \n",
    "            num_hidden_nodes=64\n",
    "        )\n",
    "        self._discriminator = BaselineModel(\n",
    "            num_inputs=1,\n",
    "            num_hidden_layers=10,\n",
    "            num_hidden_nodes=64,\n",
    "            final_activation=False,\n",
    "        )\n",
    "        self._grad_reversal = RevGrad()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self._classifier(x)\n",
    "        z_pred = self._discriminator(self._grad_reversal(y_pred))\n",
    "        return y_pred, z_pred\n",
    "    \n",
    "    def compute_loss(self, output, y, weights, z):\n",
    "        y_pred, z_pred = output\n",
    "        bce = nn.BCELoss(weight=weights)(y_pred.flatten(), y)\n",
    "        mse = ((z_pred.flatten() - z)**2 * weights).sum() / len(weights)\n",
    "        return bce + self._lambda_weight * mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5a187649",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44080859fd5c4e87a766a554a1cf2140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 0.04527, accuracy = 0.91872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss = 0.02266, accuracy = 0.93965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss = 0.02111, accuracy = 0.94312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss = 0.02020, accuracy = 0.94561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss = 0.01957, accuracy = 0.94729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: loss = 0.01897, accuracy = 0.94894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: loss = 0.01858, accuracy = 0.95019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss = 0.01837, accuracy = 0.95072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: loss = 0.01812, accuracy = 0.95171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss = 0.01784, accuracy = 0.95254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: loss = 0.01771, accuracy = 0.95310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: loss = 0.01750, accuracy = 0.95400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: loss = 0.01738, accuracy = 0.95425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: loss = 0.01724, accuracy = 0.95482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: loss = 0.01719, accuracy = 0.95501\n"
     ]
    }
   ],
   "source": [
    "adv_model = train_or_load(\n",
    "    AdversarialModel(lambda_weight=1).to(dev),\n",
    "    num_epochs=15,\n",
    "    batch_size=2048,\n",
    "    #include_z=True,\n",
    "    Optimizer=lambda *a, **k: torch.optim.RMSprop(*a, **k, lr=0.001, alpha=0.9),\n",
    "    path='data/model.adv.pt',\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e2e51eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473b7dcd47334bf28ea0f63d8097ae98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(accuracy=0.9587570650266436, loss=4.258731494854617e-06)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(adv_model, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1f9364c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/model.adv.pt', 'wb') as f:\n",
    "    torch.save(adv_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db697c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
